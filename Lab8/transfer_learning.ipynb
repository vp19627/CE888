{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNtZuKWGc55ahHIHAS1bnk0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vp19627/CE888/blob/master/Lab8/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzOILzAkO7CG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4ae5f41a-4509-40a3-8bca-fcd9f3a4d146"
      },
      "source": [
        "# Clone this repository to bring data to your virtual machine\n",
        "!git clone https://github.com/sagihaider/CE888_2020.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CE888_2020'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 25162 (delta 36), reused 4 (delta 0), pack-reused 25082\u001b[K\n",
            "Receiving objects: 100% (25162/25162), 562.19 MiB | 42.53 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yktFeUEtocQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "18ebc70c-1041-455b-fc29-77c7b55b1a17"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"vasileiospanagaris\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"a7708750cb58bbb787755a13253dbfb8\" # key from the json file\n",
        "!kaggle datasets download -d tourist55/alzheimers-dataset-4-class-of-images"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading alzheimers-dataset-4-class-of-images.zip to /content\n",
            " 73% 25.0M/34.1M [00:00<00:00, 46.4MB/s]\n",
            "100% 34.1M/34.1M [00:00<00:00, 58.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pSWo91NpBTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6ea5546-95fd-495f-bfff-383d029549e3"
      },
      "source": [
        "# Unzip the data from the zipped file\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/alzheimers-dataset-4-class-of-images.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq1q92XGpFSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "9e292555-b2c5-4b9d-dcea-fe26b9a6b8f2"
      },
      "source": [
        "!pip install tensorflow==1.3.0\n",
        "!pip install keras==2.0.7"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/7c/9f/57e1404fc9345759e4a732c4ab48ab4dd78fd1e60ee1270442b8850fa75f/tensorflow-1.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3.0) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3.0) (1.18.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3.0) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3.0) (3.10.0)\n",
            "Requirement already satisfied: tensorflow-tensorboard<0.2.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3.0) (0.1.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.3.0) (46.0.0)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3.0) (1.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3.0) (1.0.0)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3.0) (0.9999999)\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow\n",
            "  Found existing installation: tensorflow 2.1.0\n",
            "    Uninstalling tensorflow-2.1.0:\n",
            "      Successfully uninstalled tensorflow-2.1.0\n",
            "Successfully installed tensorflow-1.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.0.7 in /usr/local/lib/python3.6/dist-packages (2.0.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.0.7) (3.13)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from keras==2.0.7) (1.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from keras==2.0.7) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano->keras==2.0.7) (1.18.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano->keras==2.0.7) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3RtDt36pVS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "9d2def61-ea7a-4d69-be16-fbdb8a2f45f3"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from CE888_2020.Lab_8.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import merge, Input\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c08b2b021602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mCE888_2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLab_8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/CE888_2020/Lab_8/vgg16.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_obtain_input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_source_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_obtain_input_shape'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ69zrhepnIG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dce0dd5c-37ce-4948-b28e-a46a8a3e3f14"
      },
      "source": [
        "img_path = '/content/CE888_2020/Lab_8/elephant.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "print (x.shape)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "print (x.shape)\n",
        "x = preprocess_input(x)\n",
        "print('Input image shape:', x.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(224, 224, 3)\n",
            "(1, 224, 224, 3)\n",
            "Input image shape: (1, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znhlt-18pi42",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "968ab0ae-ff4c-4198-debf-f3fa388c63cd"
      },
      "source": [
        "#Loading the training data\n",
        "\n",
        "PATH = os.getcwd()\n",
        "# Define data path\n",
        "data_path = PATH + '/Alzheimer_s Dataset/train'\n",
        "data_dir_list = os.listdir(data_path)\n",
        "img_data_list=[]\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "\timg_list=os.listdir(data_path+'/'+ dataset)\n",
        "\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
        "\tfor img in img_list:\n",
        "\t\timg_path = data_path + '/'+ dataset + '/'+ img\n",
        "\t\timg = image.load_img(img_path, target_size=(224, 224))\n",
        "\t\tx = image.img_to_array(img)\n",
        "\t\tx = np.expand_dims(x, axis=0)\n",
        "\t\tx = preprocess_input(x)\n",
        "#\t\tx = x/255\n",
        "\t\t# print('Input image shape:', x.shape)\n",
        "\t\timg_data_list.append(x)\n",
        "\n",
        "#%% \n",
        "img_data = np.array(img_data_list)\n",
        "#img_data = img_data.astype('float32')\n",
        "print (img_data.shape)\n",
        "img_data=np.rollaxis(img_data,1,0)\n",
        "print (img_data.shape)\n",
        "img_data=img_data[0]\n",
        "print (img_data.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the images of dataset-ModerateDemented\n",
            "\n",
            "Loaded the images of dataset-MildDemented\n",
            "\n",
            "Loaded the images of dataset-NonDemented\n",
            "\n",
            "Loaded the images of dataset-VeryMildDemented\n",
            "\n",
            "(5121, 1, 224, 224, 3)\n",
            "(1, 5121, 224, 224, 3)\n",
            "(5121, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x96YCyQ3rEQU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "75de25b5-5dd4-4cdc-bd76-266ce93c41da"
      },
      "source": [
        "# Define the number of classes\n",
        "num_classes = 4\n",
        "num_of_samples = img_data.shape[0]\n",
        "labels = np.ones((num_of_samples,),dtype='int64')\n",
        "\n",
        "labels[0:202]=0\n",
        "labels[202:404]=1\n",
        "labels[404:606]=2\n",
        "labels[606:]=3\n",
        "\n",
        "names = ['ModerateDemented','MildDemented','NonDemented','VeryMildDemented']\n",
        "\n",
        "# convert class labels to on-hot encoding\n",
        "Y = np_utils.to_categorical(labels, num_classes)\n",
        "\n",
        "#Shuffle the dataset\n",
        "x,y = shuffle(img_data,Y, random_state=2)\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4bde7e325bf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m202\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Eg31jzsw2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "b7c39e59-6c9f-4889-9bcc-025ea4372e58"
      },
      "source": [
        "#%% Fine Tuning\n",
        "\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "\n",
        "model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-20f93bdbfde3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8RdQ_TptWrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_layer = model.get_layer('block5_pool').output\n",
        "x= Flatten(name='flatten')(last_layer)\n",
        "x = Dense(128, activation='relu', name='fc1')(x)\n",
        "x = Dense(128, activation='relu', name='fc2')(x)\n",
        "out = Dense(num_classes, activation='softmax', name='output')(x)\n",
        "custom_vgg_model2 = Model(image_input, out)\n",
        "custom_vgg_model2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLsF0jYctbDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freeze all the layers except the dense layers\n",
        "for layer in custom_vgg_model2.layers[:-3]:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "custom_vgg_model2.summary()\n",
        "\n",
        "custom_vgg_model2.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ajR96Jntf6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t=time.time()\n",
        "#\tt = now()\n",
        "hist = custom_vgg_model2.fit(X_train, y_train, batch_size=32, epochs=2, verbose=1, validation_data=(X_test, y_test))\n",
        "print('Training time: %s' % (t - time.time()))\n",
        "(loss, accuracy) = custom_vgg_model2.evaluate(X_test, y_test, batch_size=10, verbose=1)\n",
        "\n",
        "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvUbYU9VtlZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% plot\n",
        "import matplotlib.pyplot as plt\n",
        "# visualizing losses and accuracy\n",
        "train_loss=hist.history['loss']\n",
        "val_loss=hist.history['val_loss']\n",
        "train_acc=hist.history['acc']\n",
        "val_acc=hist.history['val_acc']\n",
        "xc=range(2)\n",
        "\n",
        "plt.figure(1,figsize=(7,5))\n",
        "plt.plot(xc,train_loss)\n",
        "plt.plot(xc,val_loss)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('train_loss vs val_loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'])\n",
        "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "plt.style.use(['classic'])\n",
        "\n",
        "plt.figure(2,figsize=(7,5))\n",
        "plt.plot(xc,train_acc)\n",
        "plt.plot(xc,val_acc)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('train_acc vs val_acc')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'],loc=4)\n",
        "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "plt.style.use(['classic'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}